{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024a58fd-12d1-4245-a08f-a1ac66b8847b",
   "metadata": {},
   "source": [
    "ASSIGNMENT ON DATA SCRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00c55e1-1f53-432a-b6e5-e22804b0206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6dc5e-ee79-4051-ae9e-e75e478fcd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33c6b8c3-8540-49f6-97e1-0d17da3ded99",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e13592-7e4d-4469-8e05-020920a4b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b16470f-f930-4797-bf99-fe7042c34bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67c7ae9-6ec2-40f0-807a-3185dcd4d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "From today's featured list\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "for tag in tags:\n",
    "    print(tag.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f78538f-8fc8-4523-9896-a20a440dc260",
   "metadata": {},
   "source": [
    "2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year\n",
    "of release) and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9dcf3af-52c9-46a0-9c6e-0104315ad192",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25313be-7440-4ee9-b924-1f014cafbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5fef714-899a-4011-ad24-b6d100f45715",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d792a90-8554-4a5d-bb6b-99e0dceb9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_containers = soup.find_all('div', class_='lister-item-content')\n",
    "names = []\n",
    "ratings = []\n",
    "years = []\n",
    "for container in movie_containers:\n",
    "    name = container.h3.a.text.strip()\n",
    "    names.append(name)\n",
    "    rating = container.find('span', class_='ipl-rating-star__rating').text.strip()\n",
    "    ratings.append(float(rating))\n",
    "    year = container.find('span', class_='lister-item-year').text.strip('()')\n",
    "    years.append(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e0ae3c-a3a7-465c-b52f-f9074f1daf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Name  Rating Year of Release\n",
      "0              The Shawshank Redemption     9.3            1994\n",
      "1                         The Godfather     9.2            1972\n",
      "2                 The Godfather Part II     9.0            1974\n",
      "3                       The Dark Knight     9.0            2008\n",
      "4                          12 Angry Men     9.0            1957\n",
      "..                                  ...     ...             ...\n",
      "95                   North by Northwest     8.3            1959\n",
      "96                   A Clockwork Orange     8.3            1971\n",
      "97                               Snatch     8.2            2000\n",
      "98  Le fabuleux destin d'Amélie Poulain     8.3            2001\n",
      "99                              The Kid     8.2            1921\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Rating': ratings,\n",
    "    'Year of Release': years\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2f7e6-8fe7-45a0-8bae-d1efb31f17e3",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name\n",
    "ii) Cuisine iii) Location iv) Ratings v) Image URL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52b792e0-b130-45e5-ab27-94e34020fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.dineout.co.in/mumbai\"\n",
    "response = requests.get(url)\n",
    "import pandas as pd\n",
    "Restaurant_name = []\n",
    "Cuisine = []\n",
    "Location = []\n",
    "Ratings = []\n",
    "Image_URL = []\n",
    "soup = BeautifulSoup(response.text, \"html\")\n",
    "restaurant = soup.find_all('div', class_='restnt-info cursor')\n",
    "for resto in restaurant:\n",
    "    name = resto.find('a', class_='restnt-name ellipsis').text.strip()\n",
    "    Restaurant_names.append(name)\n",
    "\n",
    "    cuisine = resto.find('span', class_='double-line-ellipsis').text.strip()\n",
    "    Cuisines.append(cuisine)\n",
    "\n",
    "    location = resto.find('div', class_='restnt-loc ellipsis').text.strip()\n",
    "    Location.append(location)\n",
    "    Rating = resto.find('div', class_='img-wrp').text.strip()\n",
    "    Ratings.append(float(Rating))\n",
    "    image_URL = resto.find(\"img\", class_=\"_1p7zX _1zyl5 lazy-img no-img img-loaded\").text.strip()\n",
    "    Image_URL.append(image_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98564575-7d23-4041-8eb6-f52956639525",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Restaurant_name)):\n",
    "    print(\"Restaurant_name:\", Restaurant_name[i])\n",
    "    print(\"Cuisine:\", cuisines[i])\n",
    "    print(\"Location:\", locations[i])\n",
    "    print(\"Ratings:\", ratings[i])\n",
    "    print(\"Image URL:\", image_urls[i])\n",
    "    print(\"i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fae1ac-a4d7-4066-b6f1-a76f597b26bc",
   "metadata": {},
   "source": [
    "Write s python program to display list of respected former finance minister of India(i.e.\n",
    "Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make\n",
    "data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa746b1-dc02-42e2-aebc-9f2489c7dae8",
   "metadata": {},
   "source": [
    "url = \"https://presidentofindia.nic.in/former-presidents\"\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', class_='table table-striped')\n",
    "\n",
    "names = []\n",
    "terms_of_office = []\n",
    "\n",
    "\n",
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    if len(cols) >= 2:\n",
    "        name = cols[0]\n",
    "        term_of_office = cols[1]\n",
    "        if \"Finance Minister\" in term_of_office:\n",
    "            names.append(name)\n",
    "            terms_of_office.append(term_of_office)\n",
    "data = {\n",
    "    'Name': names,\n",
    "    'Term of Office': terms_of_office\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9590d04-128f-4331-b10c-308b5e1a9a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44344bb2-67fd-434d-9c03-cb96bd1f37c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f55693-7999-4c0b-9ece-1306015c2242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6a962-7646-40c2-90c6-38454f7fdab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
