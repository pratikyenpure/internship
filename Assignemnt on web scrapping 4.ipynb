{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a109e29-6f51-4dce-bc95-437f7a454688",
   "metadata": {},
   "source": [
    "WEB SCRAPPING ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfb055-2d2e-455a-bf31-bee57292acb4",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url\n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A)\n",
    "Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e21ebb7-7552-4169-94e1-95f6a9b2d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9885d3e6-b9d2-45ed-83a9-c0ec6daf611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: \"Baby Shark Dance\"[7], Name: Pinkfong Baby Shark - Kids' Songs & Stories, Artist: 7,046,700,000, Upload Date: June 17, 2016, Views: November 2, 2020\n",
      "Rank: \"Despacito\"[10], Name: Luis Fonsi, Artist: 2,993,700,000, Upload Date: January 12, 2017, Views: August 4, 2017\n",
      "Rank: \"See You Again\"[20], Name: Wiz Khalifa, Artist: 2,894,000,000, Upload Date: April 6, 2015, Views: July 10, 2017\n",
      "Rank: \"Gangnam Style\"⁂[31], Name: Psy, Artist: 803,700,000, Upload Date: July 15, 2012, Views: November 24, 2012\n",
      "Rank: \"Baby\"*[69], Name: Justin Bieber, Artist: 245,400,000, Upload Date: February 19, 2010, Views: July 16, 2010\n",
      "Rank: \"Bad Romance\"[73], Name: Lady Gaga, Artist: 178,400,000, Upload Date: November 24, 2009, Views: April 14, 2010\n",
      "Rank: \"Charlie Bit My Finger\"[77], Name: HDCYT, Artist: 128,900,000, Upload Date: May 22, 2007, Views: October 25, 2009\n",
      "Rank: \"Evolution of Dance\"[79], Name: Judson Laipply, Artist: 118,900,000, Upload Date: April 6, 2006, Views: May 2, 2009\n",
      "Rank: \"Girlfriend\"‡[81][82], Name: RCA Records, Artist: 92,600,000, Upload Date: February 27, 2007, Views: July 17, 2008\n",
      "Rank: \"Evolution of Dance\"[79], Name: Judson Laipply, Artist: 78,400,000, Upload Date: April 6, 2006, Views: March 15, 2008\n",
      "Rank: \"Music Is My Hot Hot Sex\"‡[87], Name: CLARUSBARTEL72, Artist: 76,600,000, Upload Date: April 9, 2007, Views: March 1, 2008\n",
      "Rank: \"Evolution of Dance\"*[79], Name: Judson Laipply, Artist: 10,600,000, Upload Date: April 6, 2006, Views: May 19, 2006\n",
      "Rank: \"Pokémon Theme Music Video\"‡[92], Name: Smosh, Artist: 4,300,000, Upload Date: November 28, 2005, Views: March 12, 2006\n",
      "Rank: \"Myspace – The Movie\"‡[97][98], Name: eggtea, Artist: 2,700,000, Upload Date: January 31, 2006, Views: February 18, 2006\n",
      "Rank: \"Phony Photo Booth\"‡[101], Name: mugenized, Artist: 3,400,000, Upload Date: December 1, 2005, Views: January 21, 2006\n",
      "Rank: \"The Chronic of Narnia Rap\"‡[107], Name: youtubedude, Artist: 2,300,000, Upload Date: December 18, 2005, Views: January 9, 2006\n",
      "Rank: \"Ronaldinho: Touch of Gold\"‡*[110], Name: Nikesoccer, Artist: 255,000, Upload Date: October 21, 2005, Views: October 31, 2005\n",
      "Rank: \"I/O Brush\"‡*[116], Name: larfus, Artist: 247,000, Upload Date: October 5, 2005, Views: October 29, 2005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()  \n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "try:\n",
    "    table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table[@class='wikitable sortable']\"))\n",
    "    )\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 4:  # Check if the row has at least 5 columns\n",
    "            rank = cols[0].text\n",
    "            name = cols[1].text\n",
    "            artist = cols[2].text\n",
    "            upload_date = cols[3].text\n",
    "            views = cols[4].text\n",
    "\n",
    "            print(f\"Rank: {rank}, Name: {name}, Artist: {artist}, Upload Date: {upload_date}, Views: {views}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d46e10-fc21-4227-bc8a-3fc14398add3",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b923cd-4acf-47a5-a4c9-b508061ae530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "try:\n",
    "    fixtures_tab = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='#fixtures']\"))\n",
    "    )\n",
    "    fixtures_tab.click()\n",
    "\n",
    "    international_tab = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='#international']\"))\n",
    "    )\n",
    "    international_tab.click()\n",
    "    \n",
    "    fixtures_table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table[@class='fixtures-table']\"))\n",
    "    )\n",
    "\n",
    "    rows = fixtures_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "\n",
    "    for row in rows[1:]:  \n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 3:  # Check if the row has at least 4 columns\n",
    "            series = cols[0].text\n",
    "            place = cols[1].text\n",
    "            date = cols[2].text\n",
    "            time = cols[3].text\n",
    "\n",
    "            print(f\"Series: {series}, Place: {place}, Date: {date}, Time: {time}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd047ff3-cc25-49b8-af1e-e5a42e75d3de",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90347611-4871-4fc5-a2be-1337ca1eb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "\n",
    "try:\n",
    "  \n",
    "    economy_tab = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='#economy']\"))\n",
    "    )\n",
    "    economy_tab.click()\n",
    "\n",
    "   \n",
    "    state_wise_gdp_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='/economy/state-wise-gdp-of-india.php']\"))\n",
    "    )\n",
    "    state_wise_gdp_link.click()\n",
    "\n",
    "\n",
    "    table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table[@class='table table-striped']\"))\n",
    "    )\n",
    "\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "\n",
    "    for row in rows[1:]:  \n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 5:  # Check if the row has at least 6 columns\n",
    "            rank = cols[0].text\n",
    "            state = cols[1].text\n",
    "            gsdp_18_19 = cols[2].text\n",
    "            gsdp_19_20 = cols[3].text\n",
    "            share_18_19 = cols[4].text\n",
    "            gdp_usd_billion = cols[5].text\n",
    "\n",
    "            print(f\"Rank: {rank}, State: {state}, GSDP(18-19): {gsdp_18_19}, GSDP(19-20): {gsdp_19_20}, Share(18-19): {share_18_19}, GDP($ billion): {gdp_usd_billion}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb37bcdc-67c2-4190-9699-fdcf7bf5bbf0",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132ff442-a6b7-4123-accf-7aed6bfb33a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "\n",
    "driver.get(\"https://github.com/\")\n",
    "\n",
    "try:\n",
    "    trending_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='/trending']\"))\n",
    "    )\n",
    "    trending_button.click()\n",
    "\n",
    "    trending_list = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//article[@class='Box-row']\"))\n",
    "    )\n",
    "\n",
    "    repositories = trending_list.find_elements(By.TAG_NAME, \"article\")\n",
    "\n",
    "    for repository in repositories:\n",
    "        try:\n",
    "            \n",
    "            title = repository.find_element(By.TAG_NAME, \"h1\").text\n",
    "\n",
    "          \n",
    "            description = repository.find_element(By.TAG_NAME, \"p\").text\n",
    "\n",
    "    \n",
    "            contributors = repository.find_element(By.XPATH, \".//span[@class='text-bold']\").text\n",
    "\n",
    "\n",
    "            language = repository.find_element(By.XPATH, \".//span[@itemprop='programmingLanguage']\").text\n",
    "\n",
    "            print(f\"Repository Title: {title}, Description: {description}, Contributors: {contributors}, Language: {language}\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"Repository details not found\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74780578-2bc9-45a2-8976-9cfed07720c5",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    " Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b55c17-6d37-4833-99b6-be56a5eaf901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "\n",
    "try:\n",
    "   \n",
    "    charts_option = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='/charts']\"))\n",
    "    )\n",
    "    charts_option.click()\n",
    "\n",
    "    hot_100_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//a[@href='/charts/hot-100']\"))\n",
    "    )\n",
    "    hot_100_link.click()\n",
    "\n",
    "\n",
    "    chart_table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table[@class='chart-list']\"))\n",
    "    )\n",
    "\n",
    "\n",
    "    rows = chart_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "\n",
    "    for row in rows[1:]:  \n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 4:  # Check if the row has at least 5 columns\n",
    "            song_name = cols[1].text\n",
    "            artist_name = cols[2].text\n",
    "            last_week_rank = cols[3].text\n",
    "            peak_rank = cols[4].text\n",
    "            weeks_on_board = cols[5].text\n",
    "\n",
    "            print(f\"Song Name: {song_name}, Artist Name: {artist_name}, Last Week Rank: {last_week_rank}, Peak Rank: {peak_rank}, Weeks on Board: {weeks_on_board}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84268dc5-c065-45b8-9a15-9bea4a3b4505",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580761a1-dcda-4e16-a7c3-af3fb38acc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table[@class='table']\"))\n",
    "    )\n",
    "\n",
    " \n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 4:  # Check if the row has at least 5 columns\n",
    "            book_name = cols[0].text\n",
    "            author_name = cols[1].text\n",
    "            volumes_sold = cols[2].text\n",
    "            publisher = cols[3].text\n",
    "            genre = cols[4].text\n",
    "\n",
    "            print(f\"Book Name: {book_name}, Author Name: {author_name}, Volumes Sold: {volumes_sold}, Publisher: {publisher}, Genre: {genre}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf4507-76e3-4280-b776-720a7de88c15",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e07d351-567a-4c34-878a-982732d12536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()  \n",
    "\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "try:\n",
    "    list_items = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='lister-item mode-detail']\"))\n",
    "    )\n",
    "\n",
    "    for item in list_items:\n",
    "        name = item.find_element(By.XPATH, \".//h3/a\").text\n",
    "        year_span = item.find_element(By.XPATH, \".//h3/span[@class='lister-item-year text-muted']\").text\n",
    "        genre = item.find_element(By.XPATH, \".//span[@class='genre']\").text\n",
    "        run_time = item.find_element(By.XPATH, \".//span[@class='runtime']\").text\n",
    "        ratings = item.find_element(By.XPATH, \".//strong/span\").text\n",
    "        votes = item.find_element(By.XPATH, \".//span[@name='nv']\").text\n",
    "\n",
    "        print(f\"Name: {name}, Year Span: {year_span}, Genre: {genre}, Run Time: {run_time}, Ratings: {ratings}, Votes: {votes}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f558a4-d9cb-469e-9f7c-bbd41b82d669",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee5ff28-4f06-4b51-8cbf-6e5e4f5e5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeout exception occurred\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "\n",
    "try:\n",
    "   \n",
    "    show_all_datasets_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.LINK_TEXT, \"Show All Datasets\"))\n",
    "    )\n",
    "    show_all_datasets_button.click()\n",
    "\n",
    "   \n",
    "    datasets_table = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"datasets\"))\n",
    "    )\n",
    "\n",
    "\n",
    "    rows = datasets_table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "\n",
    "    for row in rows[1:]: \n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cols) > 6:  # Check if the row has at least 7 columns\n",
    "            dataset_name = cols[0].text\n",
    "            data_type = cols[1].text\n",
    "            task = cols[2].text\n",
    "            attribute_type = cols[3].text\n",
    "            no_of_instances = cols[4].text\n",
    "            no_of_attributes = cols[5].text\n",
    "            year = cols[6].text\n",
    "\n",
    "            print(f\"Dataset Name: {dataset_name}, Data Type: {data_type}, Task: {task}, Attribute Type: {attribute_type}, No of Instances: {no_of_instances}, No of Attributes: {no_of_attributes}, Year: {year}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout exception occurred\")\n",
    "except NoSuchElementException:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f447a-47db-404f-bb0c-1970ef26a49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
